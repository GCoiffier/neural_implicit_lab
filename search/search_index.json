{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ImplicitLab","text":"<p>Implicitlab is a python library built on top of pytorch to ease the computation of implicit neural surfaces (INR).</p> <p></p> <p></p>"},{"location":"#features","title":"Features","text":"<ul> <li>Loading, processing and sampling of various input geometry types (point clouds, polylines, surface meshes) to generate relevant training datasets  </li> <li>Training of various neural models using various published algorithms  </li> <li>Loading and saving implicit representations by serializing pytorch models  </li> <li>Perform geometrical queries and geometry processing on INRs   </li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License</p> <p>Copyright (c) 2025 Guillaume Coiffier</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"utils/","title":"Utilities","text":""},{"location":"utils/#implicitlab.utils.forward_in_batches","title":"<code>forward_in_batches(model, inputs, device, compute_grad=False, batch_size=5000)</code>","text":"<p>Runs the model <code>model</code> onto the <code>inputs</code> array and returns the computed output. As the input array may be large, the function splits it in batches that are fed one after the other to the model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>the pytorch model to run</p> required <code>inputs</code> <code>ndarray | Tensor</code> <p>Input array to be fed to the model </p> required <code>device</code> <code>str</code> <p>which device the computation should be run on.</p> required <code>compute_grad</code> <code>bool</code> <p>whether to also compute and returns the gradients of the model at the input points. Defaults to False.</p> <code>False</code> <code>batch_size</code> <code>int</code> <p>Batch size for the forward computation. Defaults to 5_000.</p> <code>5000</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: the output <code>model(inputs)</code>. If <code>compute_grad</code> is set to True, also returns the gradients as another <code>numpy.ndarray</code></p>"},{"location":"utils/#implicitlab.utils.get_device","title":"<code>get_device(force_cpu=False)</code>","text":"<p>Utility function for selecting the correct pytorch device. Returns the first gpu device found on the current system if it exists and \"cpu\" otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>force_cpu</code> <code>bool</code> <p>Forces the computation to happen on the cpu. If set to False, the device returned will always be torch.device(\"cpu\"). Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>device</code> <p>torch.device: a torch device on which to run the program.</p>"},{"location":"utils/#implicitlab.utils.gradient","title":"<code>gradient(inp_tensor, out_tensor)</code>","text":"<p>Computes the gradient of the output tensor with respect to the input tensor using pytorch's autograd.</p> <p>Parameters:</p> Name Type Description Default <code>inp_tensor</code> <code>Tensor</code> <p>input tensor</p> required <code>out_tensor</code> <code>Tensor</code> <p>output tensor</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: the gradient</p>"},{"location":"data_management/field_computations/","title":"Implicit fields","text":"<p><code>FieldGenerator</code> objects are given to a <code>PointSampler</code> object to be called on all the sampled points.</p>"},{"location":"data_management/field_computations/#example","title":"Example","text":"<pre><code>import implicitlab as IL\n\nsampler = PointSampler(\n    geometry, # some loaded geometry\n    IL.sampling_strategy.UniformBox(geometry), # the sampling strategy\n    IL.fields.Occupancy(geometry, v_in=-1, v_out=1, v_on=-1) # the field to compute\n)\npoints, field_values = sampler.sampler(10_000) \n</code></pre> <p>This example wil sample 10k points uniformly in a bounding box around the geometry object. It returns the points and an occupancy value for each point.</p>"},{"location":"data_management/field_computations/#available-fields","title":"Available fields","text":""},{"location":"data_management/field_computations/#implicitlab.data.fields.distance.Distance","title":"<code>Distance(geom, signed=True, square=False)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>geom</code> <code>Mesh</code> <p>description</p> required <code>signed</code> <code>bool</code> <p>description. Defaults to True.</p> <code>True</code> <code>square</code> <code>bool</code> <p>description. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>UnsupportedGeometryFormat</code> <p>description</p>"},{"location":"data_management/field_computations/#implicitlab.data.fields.occupancy.Occupancy","title":"<code>Occupancy(geom, v_in, v_out, v_on)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>geom</code> <code>Mesh</code> <p>description</p> required <code>v_in</code> <code>float</code> <p>description</p> required <code>v_out</code> <code>float</code> <p>description</p> required <code>v_on</code> <code>float</code> <p>description</p> required <p>Raises:</p> Type Description <code>UnsupportedGeometryFormat</code> <p>description</p> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p>"},{"location":"data_management/field_computations/#implicitlab.data.fields.winding_number.WindingNumber","title":"<code>WindingNumber(geom)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>geom</code> <code>Mesh</code> <p>description</p> required <p>Raises:</p> Type Description <code>UnsupportedGeometryFormat</code> <p>description</p> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p> References <ul> <li>Fast winding numbers for soups and clouds, Barill et al., 2018  </li> <li>https://libigl.github.io/libigl-python-bindings/igl_docs/#fast_winding_number_for_points</li> </ul>"},{"location":"data_management/field_computations/#implicitlab.data.fields.nearest.Nearest","title":"<code>Nearest(geom)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>geom</code> <code>Mesh</code> <p>description</p> required <p>Raises:</p> Type Description <code>UnsupportedGeometryFormat</code> <p>description</p> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p>"},{"location":"data_management/field_computations/#implicitlab.data.fields.misc.Constant","title":"<code>Constant(value)</code>","text":"<p>               Bases: <code>FieldGenerator</code></p> <p>summary</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>float</code> <p>description</p> required"},{"location":"data_management/field_computations/#implicitlab.data.fields.misc.Constant.compute_on","title":"<code>compute_on(query)</code>","text":"<p>summary</p> Note <p>Defining this function is optional. By default, <code>compute_on(query)</code> returns the value of <code>compute(query)</code>. Since values of a field are sometimes known for query points on the geometry (for instance: a distance field has value 0 on the surface), it can be useful to avoid the field computation and overwrite this function.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>ndarray</code> <p>the query points</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: the value of the field at each query point.</p>"},{"location":"data_management/field_computations/#implicitlab.data.fields.misc.CustomFunction","title":"<code>CustomFunction(fun, fun_on=None)</code>","text":"<p>               Bases: <code>FieldGenerator</code></p> <p>summary</p> <p>Parameters:</p> Name Type Description Default <code>fun</code> <code>Callable</code> <p>description</p> required <code>fun_on</code> <code>Callable</code> <p>description. Defaults to None.</p> <code>None</code>"},{"location":"data_management/field_computations/#make-your-custom-field","title":"Make your custom field","text":"<p>The list of possible fields can be expanded by writing a custom class that inherits from the base abstract class <code>FieldGenerator</code>.</p> <p>The custom class only needs to define the <code>compute</code> method. Additionnally, the <code>compute_on</code> method can be provided.</p>"},{"location":"data_management/field_computations/#implicitlab.data.fields.base.FieldGenerator","title":"<code>FieldGenerator</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for an implicit field.</p>"},{"location":"data_management/field_computations/#implicitlab.data.fields.base.FieldGenerator.compute","title":"<code>compute(query)</code>  <code>abstractmethod</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>ndarray</code> <p>the query points</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: the value of the field at each query point</p>"},{"location":"data_management/field_computations/#implicitlab.data.fields.base.FieldGenerator.compute_on","title":"<code>compute_on(query)</code>","text":"<p>summary</p> Note <p>Defining this function is optional. By default, <code>compute_on(query)</code> returns the value of <code>compute(query)</code>. Since values of a field are sometimes known for query points on the geometry (for instance: a distance field has value 0 on the surface), it can be useful to avoid the field computation and overwrite this function.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>ndarray</code> <p>the query points</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: the value of the field at each query point.</p>"},{"location":"data_management/point_sampling/","title":"Point Sampling","text":""},{"location":"data_management/point_sampling/#the-pointsampler-class","title":"The PointSampler class","text":""},{"location":"data_management/point_sampling/#implicitlab.data.sampler.PointSampler","title":"<code>PointSampler(geom_object, sampling_strategy, field_generator=None)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>geom_object</code> <code>Mesh</code> <p>description</p> required <code>sampling_strategy</code> <code>SamplingStrategy</code> <p>description</p> required <code>field_generator</code> <code>FieldGenerator</code> <p>description. Defaults to None.</p> <code>None</code>"},{"location":"data_management/point_sampling/#implicitlab.data.sampler.PointSampler.sample","title":"<code>sample(n_points, on_ratio=0.01)</code>","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>n_points</code> <code>int</code> <p>description</p> required <code>on_ratio</code> <code>float</code> <p>description. Defaults to 0.01.</p> <code>0.01</code> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p>"},{"location":"data_management/point_sampling/#sampling-strategies","title":"Sampling strategies","text":""},{"location":"data_management/point_sampling/#implicitlab.data.sampler.CombinedStrategy","title":"<code>CombinedStrategy(strategies, weights=None)</code>","text":"<p>               Bases: <code>SamplingStrategy</code></p> <p>summary</p> <p>Parameters:</p> Name Type Description Default <code>strategies</code> <code>list</code> <p>description</p> required <code>weights</code> <code>list</code> <p>description. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>Exception</code> <p>description</p>"},{"location":"data_management/point_sampling/#implicitlab.data.sampler.Gaussian","title":"<code>Gaussian(dim, stdv)</code>","text":"<p>               Bases: <code>SamplingStrategy</code></p> <p>summary</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>int</code> <p>description</p> required <code>stdv</code> <code>float</code> <p>description</p> required"},{"location":"data_management/point_sampling/#implicitlab.data.sampler.NearGeometryGaussian","title":"<code>NearGeometryGaussian(geom_object, stdv=0.01)</code>","text":"<p>               Bases: <code>SamplingStrategy</code></p> <p>summary</p> <p>Parameters:</p> Name Type Description Default <code>geom_object</code> <code>Mesh</code> <p>description</p> required <code>stdv</code> <code>float</code> <p>description. Defaults to 1e-2.</p> <code>0.01</code>"},{"location":"data_management/point_sampling/#implicitlab.data.sampler.UniformBox","title":"<code>UniformBox(geom_object, domain=None)</code>","text":"<p>               Bases: <code>SamplingStrategy</code></p> <p>summary</p> <p>Parameters:</p> Name Type Description Default <code>geom_object</code> <code>Mesh</code> <p>description</p> required <code>domain</code> <code>AABB</code> <p>description. Defaults to None.</p> <code>None</code>"},{"location":"nn/architectures/","title":"Architectures","text":""},{"location":"nn/architectures/#regular-architectures","title":"Regular Architectures","text":""},{"location":"nn/architectures/#implicitlab.training.nn.mlp.MultiLayerPerceptron","title":"<code>MultiLayerPerceptron(dim_in, dim_hidden, n_layers, activ=nn.ReLU, final_activ=nn.Identity)</code>","text":"<p>Simple Multi-layer Perceptron.</p> <p>Parameters:</p> Name Type Description Default <code>dim_in</code> <code>int</code> <p>dimension of the input vector. Usually 2 or 3 for neural implicits.</p> required <code>dim_hidden</code> <code>int</code> <p>dimension of the hidden layers.</p> required <code>n_layers</code> <code>int</code> <p>number of hidden layers.</p> required <code>activ</code> <code>Module</code> <p>Activation function of the network. Defaults to <code>torch.nn.ReLU</code>.</p> <code>ReLU</code> <code>final_activ</code> <code>Module</code> <p>Final activation of the network, to be applied to the output before returning the value. Defaults to <code>torch.nn.Identity</code>.</p> <code>Identity</code> References <ul> <li>On the Effectiveness of Weight-Encoded Neural Implicit 3D Shapes, Davies et al., 2021</li> </ul>"},{"location":"nn/architectures/#implicitlab.training.nn.siren.SirenNet","title":"<code>SirenNet(dim_in, dim_hidden, n_layers, w0=6.0, w0_first_layer=30.0)</code>","text":"<p>Code adapted from https://github.com/MClemot/SkeletonLearning/blob/main/siren_nn.py</p> <p>Parameters:</p> Name Type Description Default <code>dim_in</code> <code>int</code> <p>dimension of the input vector. Usually 2 or 3 for neural implicits.</p> required <code>dim_hidden</code> <code>int</code> <p>dimension of the hidden layers.</p> required <code>n_layers</code> <code>int</code> <p>number of hidden layers.</p> required <code>w0</code> <code>float</code> <p>Frequency of the activation function. Defaults to 6..</p> <code>6.0</code> <code>w0_first_layer</code> <code>float</code> <p>Frequency of the activation function in the first layer. Defaults to 30.</p> <code>30.0</code> References <p>Implicit Neural Representations with Periodic Activation Functions, Sitzmann et al., 2020</p>"},{"location":"nn/architectures/#implicitlab.training.nn.phase.PhaseNet","title":"<code>PhaseNet(dim_in, dim_hidden, n_layers, FF=True, skip_in=(), geometric_init=True, radius_init=1, beta=100)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Code adapted from the original PHASE implementation</p> <p>Parameters:</p> Name Type Description Default <code>dim_in</code> <code>_type_</code> <p>description</p> required <code>dim_hidden</code> <code>_type_</code> <p>description</p> required <code>n_layers</code> <code>_type_</code> <p>description</p> required <code>FF</code> <code>bool</code> <p>description. Defaults to True.</p> <code>True</code> <code>skip_in</code> <code>tuple</code> <p>description. Defaults to ().</p> <code>()</code> <code>geometric_init</code> <code>bool</code> <p>description. Defaults to True.</p> <code>True</code> <code>radius_init</code> <code>int</code> <p>description. Defaults to 1.</p> <code>1</code> <code>beta</code> <code>int</code> <p>description. Defaults to 100.</p> <code>100</code> References <ul> <li>Phase Transitions, Distance Functions, and Implicit Neural Representations, Yaron Lipman, 2021</li> <li>https://github.com/drv-agwl/Implicit_Neural_Representation/tree/master</li> </ul>"},{"location":"nn/architectures/#lipschitz-architectures","title":"Lipschitz Architectures","text":""},{"location":"nn/architectures/#implicitlab.training.nn.lipschitz.DenseLipAOL","title":"<code>DenseLipAOL(dim_in, dim_hidden, n_layers, coeff_lip=1.0, activation=nn.ReLU())</code>","text":"<p>Neural network made of Semi-Definite Programming neural layers, as proposed by [1]. Using a square matrix \\(W \\in \\mathbb{R}^{k \\times k}\\) and a bias vector \\(b \\in \\mathbb{R}^k\\), each layer is defined as:</p> \\[x \\mapsto \\sigma(WT^{-1/2}x + b)\\] <p>where \\(T\\) is a diagonal matrix of size \\(\\mathbb{R}^{k \\times k}\\):</p> \\[ T_{ii} = \\sum_{j=1}^k \\left| (W^T W)_{ij}\\right|\\] <p>and \\(\\sigma(x) = \\max(0, x)\\) is any 1-Lipschitz function.</p> <p>Parameters:</p> Name Type Description Default <code>dim_in</code> <code>int</code> <p>dimension of the input vector. Usually 2 or 3 for neural implicits.</p> required <code>dim_hidden</code> <code>int</code> <p>dimension of the hidden layers.</p> required <code>n_layers</code> <code>int</code> <p>number of hidden layers.</p> required <code>coeff_lip</code> <code>float</code> <p>Lipschitz constant. Defaults to 1.</p> <code>1.0</code> <code>activation</code> <code>Module</code> <p>Activation function to consider. Defaults to nn.ReLU().</p> <code>ReLU()</code> References <p>Almost-Orthogonal Layers for\u00a0Efficient General-Purpose Lipschitz Networks, Prach and Lampert, 2022</p>"},{"location":"nn/architectures/#implicitlab.training.nn.lipschitz.DenseLipBjorck","title":"<code>DenseLipBjorck(dim_in, dim_hidden, n_layers, group_sort_size=0, k_coeff_lip=1.0)</code>","text":"<p>A Lipschitz neural architecture based on Bj\u00f6rck's orthonormalization. The implementation is based on the <code>SpectralLinear</code> layer of the deel-torchlip library.</p> <p>Parameters:</p> Name Type Description Default <code>dim_in</code> <code>int</code> <p>dimension of the input vector. Usually 2 or 3 for neural implicits.</p> required <code>dim_hidden</code> <code>int</code> <p>dimension of the hidden layers.</p> required <code>n_layers</code> <code>int</code> <p>number of hidden layers.</p> required <code>group_sort_size</code> <code>int</code> <p>Size of the GroupSort activation function. If set to zero, the activation will be a FullSort. Defaults to 0.</p> <code>0</code> <code>k_coeff_lip</code> <code>float</code> <p>Lipschitz constant of the network. Defaults to 1.</p> <code>1.0</code> References <ul> <li>Sorting out Lipschitz function approximation, Anil et al., 2019</li> <li>https://github.com/deel-ai/deel-torchlip</li> </ul>"},{"location":"nn/architectures/#implicitlab.training.nn.lipschitz.DenseLipSDP","title":"<code>DenseLipSDP(dim_in, dim_hidden, n_layers, coeff_lip=1.0, activation=nn.ReLU())</code>","text":"<p>Neural network made of Semi-Definite Programming neural layers, as proposed by [1]. Using a square matrix \\(W \\in \\mathbb{R}^{k \\times k}\\), a bias vector \\(b \\in \\mathbb{R}^k\\) and an additional vector \\(q \\in \\mathbb{R}^k\\) as parameters, each layer is defined as:</p> \\[x \\mapsto x - 2WT^{-1} \\sigma(W^Tx + b)\\] <p>where \\(T\\) is a diagonal matrix of size \\(\\mathbb{R}^{k \\times k}\\):</p> \\[ T_{ii} = \\sum_{j=1}^k \\left| (W^T W)_{ij} \\,\\exp(q_j - q_i) \\right|\\] <p>and \\(\\sigma(x) = \\max(0, x)\\) is the rectified linear unit (ReLU) function. </p> <p>Parameters:</p> Name Type Description Default <code>dim_in</code> <code>int</code> <p>dimension of the input vector. Usually 2 or 3 for neural implicits.</p> required <code>dim_hidden</code> <code>int</code> <p>dimension of the hidden layers.</p> required <code>n_layers</code> <code>int</code> <p>number of hidden layers.</p> required <code>coeff_lip</code> <code>float</code> <p>Lipschitz constant. Defaults to 1.</p> <code>1.0</code> <code>activation</code> <code>Module</code> <p>Activation function. This architecture is proven to be 1-Lipschitz for ReLU, sigmoid and tanh. Defaults to ReLU.</p> <code>ReLU()</code> References <p>[1] A Unified Algebraic Perspective on Lipschitz Neural Networks, Araujo et al., 2023</p>"},{"location":"nn/architectures/#utilities","title":"Utilities","text":""},{"location":"nn/architectures/#implicitlab.training.nn.utils.count_parameters","title":"<code>count_parameters(model)</code>","text":"<p>Counts the number of optimizable parameters inside a pytorch neural network.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>the neural model to consider</p> required <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>number of optimizable parameters in the model</p>"},{"location":"nn/encodings/","title":"Input Encodings","text":"<p>Encodings are a fixed transformation applied to the input before being fed into a neural network</p>"},{"location":"nn/encodings/#usage","title":"Usage","text":"<p>When defining a neural model, simply use a <code>nn.Sequential</code> object to add your encoding before your neural network. Note that the encoding size and the input dimension of the network should match.</p> <pre><code>model = torch.nn.Sequential(\n    RandomFourierEncoding(geometry,1000),\n    MultiLayerPerceptron(1000, 128, 4)\n)\n</code></pre>"},{"location":"nn/encodings/#available-encodings","title":"Available encodings","text":""},{"location":"nn/encodings/#implicitlab.training.nn.encodings.GaussianEncoding","title":"<code>GaussianEncoding(geometry, n_points, sample_on_surface=True, stdv=1.0)</code>","text":"<p>               Bases: <code>PointDistanceEncoding</code></p> <p>Variant of the PointDistanceEncoding where distance are then fed into a Gaussian kernel:</p> \\[x \\mapsto e^{ - \\frac{||x-p||^2}{\\sigma}}\\] <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>Mesh</code> <p>the input geometry.</p> required <code>n_points</code> <code>int</code> <p>number of considered points.</p> required <code>sample_on_surface</code> <code>bool</code> <p>whether to sample the points on the geometry's surface, or at random in space. Defaults to True.</p> <code>True</code>"},{"location":"nn/encodings/#implicitlab.training.nn.encodings.HalfPlaneEncoding","title":"<code>HalfPlaneEncoding(geometry, n_points)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Encoding that considers points with normals sampled on the geometry and applies the signed distance to each corresponding hyperplanes:</p> \\[x \\mapsto \\langle n, x-p \\rangle\\] <p>where \\((p,n)\\) are points and normals.</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>Mesh</code> <p>the input geometry.</p> required <code>n_points</code> <code>int</code> <p>number of considered (point,normal) pairs.</p> required"},{"location":"nn/encodings/#implicitlab.training.nn.encodings.PointDistanceEncoding","title":"<code>PointDistanceEncoding(geometry, n_points, sample_on_surface=True)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Encodes the input point x with its l2 distance to sampled points \\(p\\) in space:</p> \\[x \\mapsto ||x-p||_2\\] <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>Mesh</code> <p>the input geometry.</p> required <code>n_points</code> <code>int</code> <p>number of considered points.</p> required <code>sample_on_surface</code> <code>bool</code> <p>whether to sample the points on the geometry's surface, or at random in space. Defaults to True.</p> <code>True</code>"},{"location":"nn/encodings/#implicitlab.training.nn.encodings.RandomFourierEncoding","title":"<code>RandomFourierEncoding(geometry, dim_encoded, stdv=1.0)</code>","text":"<p>               Bases: <code>Module</code></p> <p>Encodes a given position into different frequencies of trigonometric functions :</p> \\[x \\mapsto [\\cos(2\\pi b x), \\sin(2 \\pi b x)]\\] <p>where \\(b\\) is sampled from a normal distribution of zero mean (and provided standard deviation)</p> <p>Parameters:</p> Name Type Description Default <code>geometry</code> <code>Mesh</code> <p>the input geometry. Only the dimensionality attribute (<code>geometry.dim</code>) is accessed, but argument is kept for consistency with other encodings.</p> required <code>dim_encoded</code> <code>int</code> <p>size of the final encoded vector. Should be an even number (as both sin and cos of every frequency is computed). the tensor <code>b</code> will have shape <code>(geometry.dim, dim_encoded//2)</code></p> required <code>stdv</code> <code>float</code> <p>Standard variation of the normal distribution used to compute <code>b</code>. Defaults to 1..</p> <code>1.0</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Fails if the encoding size is not an even number.</p> References <ul> <li>Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains, Tancik et al. (2020) : https://arxiv.org/abs/2006.10739</li> <li>https://github.com/jmclong/random-fourier-features-pytorch/tree/main</li> </ul>"},{"location":"nn/loading_saving_models/","title":"Loading and saving neural models","text":""},{"location":"nn/loading_saving_models/#implicitlab.training.nn.io.load_model","title":"<code>load_model(path, device='cpu')</code>","text":"<p>Loads a neural model from the disk.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>file path to the saved file</p> required <code>device</code> <code>str</code> <p>device onto which the model is loaded. Defaults to \"cpu\".</p> <code>'cpu'</code> <p>Returns:</p> Type Description <code>Module</code> <p>torch.nn.Module: the loaded neural model</p>"},{"location":"nn/loading_saving_models/#implicitlab.training.nn.io.save_model","title":"<code>save_model(model, path)</code>","text":"<p>Saves a neural model onto the disk.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>neural model to be saved</p> required <code>path</code> <code>str</code> <p>file path to the saved file.</p> required"},{"location":"queries/queries/","title":"Geometrical queries","text":""},{"location":"queries/queries/#implicitlab.queries.queries.gradient_descent","title":"<code>gradient_descent(query_pts, model, device='cpu', step_size=1.0, batch_size=1000, use_dist=False, normalize_grad=False, max_steps=100)</code>","text":"<p>Performs steps of gradient descent of the given neural implicit function.</p> <p>Parameters:</p> Name Type Description Default <code>query_pts</code> <code>ndarray</code> <p>starting points.</p> required <code>model</code> <code>Module</code> <p>the neural implicit function.</p> required <code>device</code> <code>str</code> <p>device onto which the computation is performed. Defaults to \"cpu\".</p> <code>'cpu'</code> <code>step_size</code> <code>float</code> <p>multiplicative parameter of the gradient at each step (\"learning rate\"). Defaults to 1..</p> <code>1.0</code> <code>batch_size</code> <code>int</code> <p>batch size for forward/backward computation on the neural implicit. Defaults to 1000.</p> <code>1000</code> <code>use_dist</code> <code>bool</code> <p>whether to multiply the step by the value of the function at each point. Defaults to False.</p> <code>False</code> <code>normalize_grad</code> <code>bool</code> <p>whether to normalize the neural implicit gradient at each steps. Defaults to False.</p> <code>False</code> <code>max_steps</code> <code>int</code> <p>maximum number of steps. Defaults to 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: output points</p>"},{"location":"queries/queries/#implicitlab.queries.queries.project_onto_iso","title":"<code>project_onto_iso(query_pts, model, iso=0.0, device='cpu', batch_size=1000, normalize_grad=False, max_steps=100, precision=1e-06)</code>","text":"<p>Project the input points onto the nearest point of a given isosurface.</p> <p>Parameters:</p> Name Type Description Default <code>query_pts</code> <code>ndarray</code> <p>input point</p> required <code>model</code> <code>Module</code> <p>the neural implicit function.</p> required <code>iso</code> <code>float</code> <p>which isovalue the points should be projected to. Defaults to 0..</p> <code>0.0</code> <code>device</code> <code>str</code> <p>device onto which the computation is performed. Defaults to \"cpu\".</p> <code>'cpu'</code> <code>batch_size</code> <code>int</code> <p>batch size for forward/backward computation on the neural implicit. Defaults to 1000.</p> <code>1000</code> <code>normalize_grad</code> <code>bool</code> <p>whether to normalize the neural implicit gradient at each steps. Defaults to False.</p> <code>False</code> <code>max_steps</code> <code>int</code> <p>maximum number of steps. Defaults to 100.</p> <code>100</code> <code>precision</code> <code>float</code> <p>. Defaults to 1e-6.</p> <code>1e-06</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: the projected points</p>"},{"location":"queries/queries/#implicitlab.queries.queries.sample_iso_projection","title":"<code>sample_iso_projection(init_pts, model, iso=0.0, device='cpu', n_nearest=10, stdv=0.2, step_size=0.1, batch_size=1000, normalize_grad=False, max_steps=10)</code>","text":"<p>Sample a neural implicit isosurface by projecting points onto it and make them repel themselves.</p> <p>Parameters:</p> Name Type Description Default <code>init_pts</code> <code>ndarray</code> <p>initial points to be projected onto the isosurface.</p> required <code>model</code> <code>Module</code> <p>the neural implicit function.</p> required <code>iso</code> <code>float</code> <p>which isovalue the points should be projected to. Defaults to 0..</p> <code>0.0</code> <code>device</code> <code>str</code> <p>device onto which the computation is performed. Defaults to \"cpu\".</p> <code>'cpu'</code> <code>n_nearest</code> <code>int</code> <p>number of nearest neighbors to consider for the repelling phase. Defaults to 10.</p> <code>10</code> <code>stdv</code> <code>float</code> <p>standard deviation of the weights of near samples. Defaults to 0.2.</p> <code>0.2</code> <code>step_size</code> <code>float</code> <p>multiplicative parameter of the gradient at each step (\"learning rate\"). Defaults to 1..</p> <code>0.1</code> <code>batch_size</code> <code>int</code> <p>batch size for forward/backward computation on the neural implicit. Defaults to 1000.</p> <code>1000</code> <code>normalize_grad</code> <code>bool</code> <p>whether to normalize the neural implicit gradient at each steps. Defaults to False.</p> <code>False</code> <code>max_steps</code> <code>int</code> <p>maximum number of steps. Defaults to 100.</p> <code>10</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: points sampled on the given isosurface.</p> References <p>Iso-Points: Optimizing Neural Implicit Surfaces with Hybrid Representations, Yifan et al. (2021)</p>"},{"location":"queries/queries/#implicitlab.queries.queries.sample_iso_raytraced","title":"<code>sample_iso_raytraced(model, n_rays, iso=0.0, device='cpu', threshold=0.0001)</code>","text":"<p>Sample an isosurface of a neural implicit function by tracing rays intersecting the object and returning all ray-shape intersection points.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>the neural implicit function.</p> required <code>n_rays</code> <code>int</code> <p>number of rays to sample. The number of sampled points is related to the number of rays</p> required <code>iso</code> <code>float</code> <p>description. Defaults to 0..</p> <code>0.0</code> <code>device</code> <code>str</code> <p>description. Defaults to \"cpu\".</p> <code>'cpu'</code> <code>threshold</code> <code>float</code> <p>description. Defaults to 1e-4.</p> <code>0.0001</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: sampled points</p> References <ul> <li>Uniform Sampling of Surfaces by Casting Rays, Ling et al., 2025  </li> <li>https://github.com/iszihan/implicit-uniform-sampler/blob/main/ImplicitUniformSampler/sampler.py</li> </ul>"},{"location":"queries/queries/#implicitlab.queries.queries.sample_skeleton","title":"<code>sample_skeleton(model, res, device='cpu', batch_size=1000, margin=-0.01, grad_norm_threshold=0.5, descent_steps=0)</code>","text":"<p>Samples the skeleton of a neural signed distance field. The skeleton of a shape is defined as the inside discontinuities of its distance field's gradient. This function works by sampling and rejecting points depending on the norm of the gradient at each point. If the neural implicit is well behaved (for instance, a 1-Lip SDF), then the discontinuities have low gradient.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>the neural implicit function.</p> required <code>res</code> <code>int</code> <p>resolution of the sampling.</p> required <code>device</code> <code>str</code> <p>device onto which the computation is performed. Defaults to \"cpu\".</p> <code>'cpu'</code> <code>batch_size</code> <code>int</code> <p>batch size for forward/backward computation on the neural implicit. Defaults to 1000.</p> <code>1000</code> <code>margin</code> <code>float</code> <p>the maximal value of the implicit function for a point to be considered inside the shape. Defaults to -1e-2.</p> <code>-0.01</code> <code>grad_norm_threshold</code> <code>float</code> <p>the threshold for rejecting non-skeleton points. Defaults to 0.5.</p> <code>0.5</code> <code>descent_steps</code> <code>int</code> <p>number of gradient descent step to perform on the sampled points to project them to the skeleton. Defaults to 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: sampled points on the skeleton of the shape</p>"},{"location":"queries/visualize/","title":"Visualization","text":""},{"location":"queries/visualize/#implicitlab.queries.visualize.reconstruct_surface_marching_cubes","title":"<code>reconstruct_surface_marching_cubes(model, domain, device, iso=0, res=100, batch_size=5000)</code>","text":"<p>Extracts isosurfaces of a given neural implicit by using the Marching Cube algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Module</code> <p>the neural implicit function.</p> required <code>domain</code> <code>AABB</code> <p>domain onto which the function values are computed.</p> required <code>device</code> <code>str</code> <p>device onto which the computation are performed.</p> required <code>iso</code> <code>int</code> <p>value of the isosurface. Several values can be provided in a list. If that is the case, one mesh per isovalue will be produced. Defaults to 0.</p> <code>0</code> <code>res</code> <code>int</code> <p>resolution of the marching cubes grid. Defaults to 100.</p> <code>100</code> <code>batch_size</code> <code>int</code> <p>batch size for forward computation. Defaults to 5000.</p> <code>5000</code> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>returns a dictionnary of ((i,iso), mesh) where i is a unique identifier, iso is the value of the isovalue and mesh is the output surface mesh (mouette.mesh.SurfaceMesh type).</p> References <ul> <li>Marching cubes: A high resolution 3D surface construction algorithm, Lorensen &amp; Cline (1998)  </li> <li>https://scikit-image.org/docs/0.25.x/auto_examples/edges/plot_marching_cubes.html</li> </ul>"},{"location":"queries/visualize/#implicitlab.queries.visualize.render_sdf_2d","title":"<code>render_sdf_2d(render_path, contour_path, gradient_path, model, domain, device, res=1000, batch_size=1000)</code>","text":"<p>Renders a 2D SDF</p> <p>Parameters:</p> Name Type Description Default <code>render_path</code> <code>str</code> <p>Path to export a color render</p> required <code>contour_path</code> <code>str</code> <p>Path to export the contour plot</p> required <code>gradient_path</code> <code>str</code> <p>Path to export the gradient norm plot</p> required <code>model </code> <p>SDF neural model</p> required <code>domain</code> <code>AABB</code> <p>axis aligned bounding box of dimension 2to represent the plotting domain.</p> required <code>device</code> <code>str</code> <p>cpu or cuda</p> required <code>res</code> <code>int</code> <p>Image resolution. Defaults to 800.</p> <code>1000</code> <code>batch_size</code> <code>int</code> <p>Size of forward batches. Defaults to 1000.</p> <code>1000</code>"},{"location":"queries/visualize/#implicitlab.queries.visualize.render_sdf_quad","title":"<code>render_sdf_quad(render_path, contour_path, gradient_path, model, P0, P1, P2, device, res=800, batch_size=1000, **kwargs)</code>","text":"<p>Renders a 3D sdf along a specified (planar) quad in space.</p> <p>Parameters:</p> Name Type Description Default <code>render_path</code> <code>str</code> <p>Path to export a color render</p> required <code>contour_path</code> <code>str</code> <p>Path to export the contour plot</p> required <code>gradient_path</code> <code>str</code> <p>Path to export the gradient norm plot</p> required <code>model </code> <p>SDF neural model</p> required <code>P0</code> <code>array</code> <p>First point of the quad ( (0,0) in parameter space)</p> required <code>P1</code> <code>array</code> <p>Second point of the quad ( (1,0) in parameter space)</p> required <code>P2</code> <code>array</code> <p>Thirs point of the quad ( (0,1) in parameter space)</p> required <code>device</code> <code>str</code> <p>cpu or cuda</p> required <code>res</code> <code>int</code> <p>Image resolution. Defaults to 800.</p> <code>800</code> <code>batch_size</code> <code>int</code> <p>Size of forward batches. Defaults to 1000.</p> <code>1000</code>"},{"location":"training/callbacks/","title":"Callbacks","text":"<p>Callback are small piece of logic that affect the trainer they are associated with, provide log infos, or do anything you can think of. Inside a Trainer, they can be called at four points:   </p> <ul> <li>At the beginning of an training epoch  </li> <li>At the end of an training epoch  </li> <li>At the end of a forward/backward pass  </li> <li>At the end of a testing epoch  </li> </ul> <p>Callbacks are added at the beginning of the training using the <code>add_callbacks</code> method of the <code>Trainer</code> class:</p> <pre><code>from implicitlab.training import SimpleRegressionTrainer, TrainingConfig\nfrom implicitlab.training import callbacks\n\ntrainer = SimpleRegressionTrainer(TrainingConfig(), lossfun=torch.nn.MSELoss())\ntrainer.add_callbacks(\n    callbacks.LoggerCB(\"output/training_log.txt\"), # write losses and info about training in a .txt file\n    callbacks.Render2DCB(\"output\", 10) # makes a snapshot of a 2D neural implicit every 10 training epochs\n)\n</code></pre>"},{"location":"training/callbacks/#list-of-implemented-callbacks","title":"List of implemented callbacks","text":""},{"location":"training/callbacks/#implicitlab.training.callbacks.CheckpointCB","title":"<code>CheckpointCB(save_folder, when)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>A Callback responsible for saving the model currently in training into a file</p> <p>Parameters:</p> Name Type Description Default <code>save_folder</code> <code>str</code> <p>folder into which the model will be saved. The filename if formatted as <code>model_e{epoch}.pt</code></p> required <code>when</code> <code>list</code> <p>list of epochs when the model should be saved onto dist</p> required"},{"location":"training/callbacks/#implicitlab.training.callbacks.LoggerCB","title":"<code>LoggerCB(file_path)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>Registers metrics of the training inside a .log file</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>path to the log text file.</p> required"},{"location":"training/callbacks/#implicitlab.training.callbacks.MarchingCubeCB","title":"<code>MarchingCubeCB(save_folder, freq, domain=None, res=100, iso=0)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>A Callback that makes a snapshot of a 3D neural implicit by using the marching cubes algorithm to extract some level sets.</p> <p>Parameters:</p> Name Type Description Default <code>save_folder</code> <code>str</code> <p>output folder into which the images are saved</p> required <code>freq</code> <code>int</code> <p>frequency (in terms of number of epochs) at which a snapshot is taken</p> required <code>domain</code> <code>AABB</code> <p>AABB domain over which the grid is defined. If not provided, the default domain will be [-1.2 ; 1.2]^3. Defaults to None.</p> <code>None</code> <code>res</code> <code>int</code> <p>Grid resolution for marching cubes. res^3 values will be sampled from the neural model. Defaults to 100.</p> <code>100</code> <code>iso</code> <code>int</code> <p>Which iso-level will be reconstructed. Several levels can be provided in a list. Defaults to 0.</p> <code>0</code>"},{"location":"training/callbacks/#implicitlab.training.callbacks.Render2DCB","title":"<code>Render2DCB(save_folder, freq, plot_domain=None, resolution=800, output_contours=True, output_gradient_norm=True)</code>","text":"<p>               Bases: <code>Callback</code></p> <p>A Callback that makes a snapshot of a 2D neural implicit by sampling its values on a grid. Can also sample the gradient's norm and make a contour plot.</p> <p>Parameters:</p> Name Type Description Default <code>save_folder</code> <code>str</code> <p>output folder into which the images are saved</p> required <code>freq</code> <code>int</code> <p>frequency (in terms of number of epochs) at which a snapshot is taken</p> required <code>plot_domain</code> <code>AABB</code> <p>Spanning domain of the taken snapshot.  If not provided, the domain will be taken as a default [-1.5, 1.5]^2. Defaults to None.</p> <code>None</code> <code>resolution</code> <code>int</code> <p>Resolution of the snapshot grid. resolution^2 samples will be computed from the neural implicit model. Defaults to 800.</p> <code>800</code> <code>output_contours</code> <code>bool</code> <p>Whether to output a contour plot of the neural field. Defaults to True.</p> <code>True</code> <code>output_gradient_norm</code> <code>bool</code> <p>Whether to also output a plot of the norm of the neural field's gradient. Defaults to True.</p> <code>True</code> Warning <p>Fails if the neural implicit currently training is not 2-dimensionnal.</p>"},{"location":"training/callbacks/#write-your-own-callback","title":"Write your own callback","text":"<p>All callbacks inherit from the base class <code>Callback</code>, which implements four methods:</p> <pre><code>class Callback:\n    def callOnBeginTrain(self, trainer, model): pass\n\n    def callOnEndTrain(self, trainer, model): pass\n\n    def callOnEndForward(self, trainer, model): pass\n\n    def callOnEndTest(self, trainer, model): pass\n</code></pre> <p>Every method takes as argument the trainer it's linked to, and the model the trainer is currently optimizing. Therefore, it has full information about what's going on during optimization.</p> <p>To implement our own custom callback, simply create a class that inherits from <code>Callback</code> and that implements one or several of these methods.</p>"},{"location":"training/loss_functions/","title":"Loss Functions","text":""},{"location":"training/loss_functions/#implicitlab.training.losses.EikonalLoss","title":"<code>EikonalLoss()</code>","text":"<p>The Eikonal loss regularizes the gradient of a neural implicit to have unit norm everywhere:</p> \\[\\mathcal{L}_{\\text{eik}}(x) = (||\\nabla f_\\theta(x)|| -1)^2\\] <p>The gradient is computed from the input \\(X\\) and the output \\(Y\\) of the neural model.</p>"},{"location":"training/loss_functions/#implicitlab.training.losses.EikonalLoss.__call__","title":"<code>__call__(X, Y)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>X</code> <code>Tensor</code> <p>input batch of the model</p> required <code>Y</code> <code>Tensor</code> <p>output of the model.</p> required <p>Returns:</p> Type Description <p>torch.Tensor: Eikonal loss</p>"},{"location":"training/loss_functions/#implicitlab.training.losses.HKRLoss","title":"<code>HKRLoss(margin=0.01, lmbd=10.0)</code>","text":"<p>Hinge Kantorovitch-Rubinstein loss</p> \\[\\text{hKR}(x) = \\max(0, m-x) - \\frac{x}{\\lambda}\\] <p>Parameters:</p> Name Type Description Default <code>margin</code> <code>float</code> <p>hinge margin. Must be small but not too small. Defaults to 1e-2.</p> <code>0.01</code> <code>lmbd</code> <code>float</code> <p>weight balance between the two terms.. Defaults to 10.</p> <code>10.0</code> References <ul> <li>Achieving robustness in classification using optimal transport with hinge regularization, Serrurier et al., 2021</li> <li>1-Lipschitz neural distance fields, Coiffier and B\u00e9thune, 2024</li> </ul>"},{"location":"training/loss_functions/#implicitlab.training.losses.HKRLoss.__call__","title":"<code>__call__(y)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>y</code> <code>Tensor</code> <p>vector of predicted values</p> required"},{"location":"training/loss_functions/#implicitlab.training.losses.HotspotLoss","title":"<code>HotspotLoss(lmbd)</code>","text":"\\[\\mathcal{L}_{\\text{heat}}(f) = \\mathbb{E}_x \\left[ e^{-2 \\lambda |f(x)|} \\left( || \\nabla f||^2 + 1 \\right) \\right].\\] References <ul> <li>HotSpot: Signed Distance Function Optimization with an Asymptotically Sufficient Condition, Wang et al., 2025</li> </ul>"},{"location":"training/loss_functions/#implicitlab.training.losses.SALDLoss","title":"<code>SALDLoss()</code>","text":"<p>Sign agnostic learning loss with derivatives</p> References <p>SALD: Sign Agnostic Learning with Derivatives, Atzmon and Lipman, 2020</p>"},{"location":"training/loss_functions/#implicitlab.training.losses.SALDLoss.__call__","title":"<code>__call__(y_pred, y_target)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>Tensor</code> <p>predicted values by the model</p> required <code>y_target</code> <code>Tensor</code> <p>target values</p> required"},{"location":"training/loss_functions/#implicitlab.training.losses.SALLoss","title":"<code>SALLoss(l=1.0, metric='l2')</code>","text":"<p>Signed agnostic learning loss.</p> <p>Parameters:</p> Name Type Description Default <code>l</code> <code>float</code> <p>Power value for the distance. Defaults to 1.</p> <code>1.0</code> <code>metric</code> <code>str</code> <p>which metric to use. Choices are \"l2\" and \"l0\". Defaults to \"l2\".</p> <code>'l2'</code> References <p>SAL: Sign Agnostic Learning of Shapes From Raw Data, Atzmon and Lipman, 2020</p>"},{"location":"training/loss_functions/#implicitlab.training.losses.SALLoss.__call__","title":"<code>__call__(y_pred, y_target)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>y_pred</code> <code>Tensor</code> <p>predicted values by the model</p> required <code>y_target</code> <code>Tensor</code> <p>target values</p> required"},{"location":"training/loss_functions/#implicitlab.training.losses.SingularHessianLoss","title":"<code>SingularHessianLoss</code>","text":"<p>TODO</p>"},{"location":"training/loss_functions/#implicitlab.training.losses.ThinPlateLoss","title":"<code>ThinPlateLoss</code>","text":"References <ul> <li>NeuVAS: Neural Implicit Surfaces for Variational Shape Modeling, Wang et al., 2025</li> <li>https://github.com/GeometryArt/NeuVAS/tree/main/code</li> </ul>"},{"location":"training/loss_functions/#implicitlab.training.losses.VectorAlignmentLoss","title":"<code>VectorAlignmentLoss()</code>","text":"<p>Cosine similarity loss between two vectors.</p>"},{"location":"training/loss_functions/#implicitlab.training.losses.VectorAlignmentLoss.__call__","title":"<code>__call__(y, target)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>y</code> <code>Tensor</code> <p>input tensor</p> required <code>target</code> <code>Tensor</code> <p>target tensor</p> required <p>Returns:</p> Type Description <p>torch.Tensor: Cosine similarity</p>"},{"location":"tutorial/geometrical_queries/","title":"Geometrical queries","text":""},{"location":"tutorial/geometrical_queries/#installation","title":"Installation","text":""},{"location":"tutorial/geometrical_queries/#_1","title":"Geometrical queries","text":""},{"location":"tutorial/geometrical_queries/#a-full-example-sirennet","title":"A full example: SIRENNet","text":""},{"location":"tutorial/geometrical_queries/#setting-up-the-data","title":"Setting up the data","text":""},{"location":"tutorial/geometrical_queries/#train-a-model","title":"Train a model","text":""},{"location":"tutorial/geometrical_queries/#another-example-lipschitz-distance-fields","title":"Another example: Lipschitz distance fields","text":""},{"location":"tutorial/geometrical_queries/#setting-up-the-data_1","title":"Setting up the data","text":""},{"location":"tutorial/geometrical_queries/#train-a-model_1","title":"Train a model","text":""},{"location":"tutorial/installation/","title":"Installation","text":""},{"location":"tutorial/installation/#dependencies","title":"Dependencies","text":"<p>todo</p>"},{"location":"tutorial/preparing_dataset/","title":"Preparing dataset","text":""},{"location":"tutorial/preparing_dataset/#installation","title":"Installation","text":""},{"location":"tutorial/preparing_dataset/#_1","title":"Preparing dataset","text":""},{"location":"tutorial/preparing_dataset/#a-full-example-sirennet","title":"A full example: SIRENNet","text":""},{"location":"tutorial/preparing_dataset/#setting-up-the-data","title":"Setting up the data","text":""},{"location":"tutorial/preparing_dataset/#train-a-model","title":"Train a model","text":""},{"location":"tutorial/preparing_dataset/#another-example-lipschitz-distance-fields","title":"Another example: Lipschitz distance fields","text":""},{"location":"tutorial/preparing_dataset/#setting-up-the-data_1","title":"Setting up the data","text":""},{"location":"tutorial/preparing_dataset/#train-a-model_1","title":"Train a model","text":""},{"location":"tutorial/training_model/","title":"Training model","text":""},{"location":"tutorial/training_model/#installation","title":"Installation","text":""},{"location":"tutorial/training_model/#_1","title":"Training model","text":""},{"location":"tutorial/training_model/#a-full-example-sirennet","title":"A full example: SIRENNet","text":""},{"location":"tutorial/training_model/#setting-up-the-data","title":"Setting up the data","text":""},{"location":"tutorial/training_model/#train-a-model","title":"Train a model","text":""},{"location":"tutorial/training_model/#another-example-lipschitz-distance-fields","title":"Another example: Lipschitz distance fields","text":""},{"location":"tutorial/training_model/#setting-up-the-data_1","title":"Setting up the data","text":""},{"location":"tutorial/training_model/#train-a-model_1","title":"Train a model","text":""}]}